{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3de461e1",
   "metadata": {},
   "source": [
    "# Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39badab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9355a142",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = torch.FloatTensor([[.1, .2, .3],\n",
    "                            [.4, .5, .6],\n",
    "                            [.7, .8, .9]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4fe1c048",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6950, 0.7197, 0.9521],\n",
       "        [0.1065, 0.4996, 0.3385],\n",
       "        [0.4921, 0.2137, 0.8907]], requires_grad=True)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand_like(target).requires_grad_(True)\n",
    "\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04e937c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_loss = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7cdbac3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1768, grad_fn=<MseLossBackward>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = mse_loss(x, target)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6699aff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1th Loss: 0.10693342983722687\n",
      "tensor([[0.5628, 0.6042, 0.8072],\n",
      "        [0.1717, 0.4997, 0.3966],\n",
      "        [0.5383, 0.3440, 0.8928]], requires_grad=True)\n",
      "2th Loss: 0.06468811631202698\n",
      "tensor([[0.4599, 0.5144, 0.6945],\n",
      "        [0.2224, 0.4998, 0.4418],\n",
      "        [0.5743, 0.4453, 0.8944]], requires_grad=True)\n",
      "3th Loss: 0.03913232311606407\n",
      "tensor([[0.3800, 0.4445, 0.6068],\n",
      "        [0.2619, 0.4998, 0.4770],\n",
      "        [0.6022, 0.5242, 0.8956]], requires_grad=True)\n",
      "4th Loss: 0.023672640323638916\n",
      "tensor([[0.3177, 0.3902, 0.5386],\n",
      "        [0.2926, 0.4999, 0.5043],\n",
      "        [0.6239, 0.5855, 0.8966]], requires_grad=True)\n",
      "5th Loss: 0.014320486225187778\n",
      "tensor([[0.2694, 0.3479, 0.4856],\n",
      "        [0.3165, 0.4999, 0.5256],\n",
      "        [0.6408, 0.6331, 0.8974]], requires_grad=True)\n",
      "6th Loss: 0.008663009852170944\n",
      "tensor([[0.2317, 0.3151, 0.4444],\n",
      "        [0.3350, 0.4999, 0.5421],\n",
      "        [0.6540, 0.6702, 0.8979]], requires_grad=True)\n",
      "7th Loss: 0.005240586120635271\n",
      "tensor([[0.2024, 0.2895, 0.4123],\n",
      "        [0.3495, 0.4999, 0.5550],\n",
      "        [0.6642, 0.6991, 0.8984]], requires_grad=True)\n",
      "8th Loss: 0.0031702308915555477\n",
      "tensor([[0.1797, 0.2696, 0.3873],\n",
      "        [0.3607, 0.4999, 0.5650],\n",
      "        [0.6722, 0.7215, 0.8988]], requires_grad=True)\n",
      "9th Loss: 0.0019177932990714908\n",
      "tensor([[0.1620, 0.2541, 0.3679],\n",
      "        [0.3694, 0.5000, 0.5728],\n",
      "        [0.6783, 0.7389, 0.8990]], requires_grad=True)\n",
      "10th Loss: 0.0011601460864767432\n",
      "tensor([[0.1482, 0.2421, 0.3528],\n",
      "        [0.3762, 0.5000, 0.5788],\n",
      "        [0.6832, 0.7525, 0.8992]], requires_grad=True)\n",
      "11th Loss: 0.0007018166361376643\n",
      "tensor([[0.1375, 0.2327, 0.3411],\n",
      "        [0.3815, 0.5000, 0.5835],\n",
      "        [0.6869, 0.7631, 0.8994]], requires_grad=True)\n",
      "12th Loss: 0.0004245556192472577\n",
      "tensor([[0.1292, 0.2255, 0.3320],\n",
      "        [0.3856, 0.5000, 0.5872],\n",
      "        [0.6898, 0.7713, 0.8995]], requires_grad=True)\n",
      "13th Loss: 0.0002568298950791359\n",
      "tensor([[0.1227, 0.2198, 0.3249],\n",
      "        [0.3888, 0.5000, 0.5900],\n",
      "        [0.6921, 0.7777, 0.8996]], requires_grad=True)\n",
      "14th Loss: 0.00015536631690338254\n",
      "tensor([[0.1176, 0.2154, 0.3193],\n",
      "        [0.3913, 0.5000, 0.5922],\n",
      "        [0.6938, 0.7826, 0.8997]], requires_grad=True)\n",
      "15th Loss: 9.398697147844359e-05\n",
      "tensor([[0.1137, 0.2120, 0.3150],\n",
      "        [0.3932, 0.5000, 0.5940],\n",
      "        [0.6952, 0.7865, 0.8998]], requires_grad=True)\n",
      "16th Loss: 5.6856402807170525e-05\n",
      "tensor([[0.1107, 0.2093, 0.3117],\n",
      "        [0.3947, 0.5000, 0.5953],\n",
      "        [0.6963, 0.7895, 0.8998]], requires_grad=True)\n",
      "17th Loss: 3.4394601243548095e-05\n",
      "tensor([[0.1083, 0.2072, 0.3091],\n",
      "        [0.3959, 0.5000, 0.5964],\n",
      "        [0.6971, 0.7918, 0.8999]], requires_grad=True)\n",
      "18th Loss: 2.080656668113079e-05\n",
      "tensor([[0.1065, 0.2056, 0.3071],\n",
      "        [0.3968, 0.5000, 0.5972],\n",
      "        [0.6977, 0.7936, 0.8999]], requires_grad=True)\n",
      "19th Loss: 1.2586719094542786e-05\n",
      "tensor([[0.1050, 0.2044, 0.3055],\n",
      "        [0.3975, 0.5000, 0.5978],\n",
      "        [0.6982, 0.7951, 0.8999]], requires_grad=True)\n",
      "20th Loss: 7.614221885887673e-06\n",
      "tensor([[0.1039, 0.2034, 0.3043],\n",
      "        [0.3981, 0.5000, 0.5983],\n",
      "        [0.6986, 0.7962, 0.8999]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "threshold = 1e-5\n",
    "learning_rate = 1.\n",
    "iter_cnt = 0\n",
    "\n",
    "while loss > threshold:\n",
    "    iter_cnt += 1\n",
    "    \n",
    "    loss.backward() ## calculate gradients.\n",
    "    \n",
    "    x = x - learning_rate * x.grad\n",
    "    \n",
    "    x.detach_()\n",
    "    x.requires_grad_(True)\n",
    "    \n",
    "    loss = mse_loss(x, target)\n",
    "    \n",
    "    print(f\"{iter_cnt}th Loss: {loss}\")\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ef9eed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
